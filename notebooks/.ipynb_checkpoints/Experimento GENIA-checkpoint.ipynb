{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30e2cbb5-7baf-47d8-8b2d-bfd5c3babc41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7a09bb7e36a0>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/sentence-transformers/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.10.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m425.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.4.0)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m673.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:24\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/huggingface-hub/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface-hub>=0.20.0\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m835.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.28.2)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m500.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:20\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nvidia-cuda-runtime-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m938.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m763.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.4.0\n",
      "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 MB\u001b[0m \u001b[31m667.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.10.2.21\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/706.8 MB\u001b[0m \u001b[31m739.3 kB/s\u001b[0m eta \u001b[36m0:15:35\u001b[0m"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d4ce376-ead2-4c11-b2fa-347d8c2536e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Añadir la carpeta src al path\n",
    "sys.path.append(os.path.join(\"..\", \"src\"))\n",
    "\n",
    "from data_loader import load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f69579-c370-4dff-a48b-b4f086b14503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from openai import OpenAI\n",
    "from data_loader import load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c458d63a-2248-49dd-bd3b-673677abb4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users, products, interactions = load_all(\n",
    "    \"../data/users.csv\",\n",
    "    \"../data/products.csv\",\n",
    "    \"../data/interactions.csv\"\n",
    ")\n",
    "\n",
    "# Combinar palabras clave y descripción para texto del producto\n",
    "products['text_features'] = products.apply(\n",
    "    lambda row: \" \".join(row['palabras_clave']) + \" \" + str(row['descripcion']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96758564-0e9b-42f6-bbcc-345e424b5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de embeddings ligero\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "product_embeddings = embed_model.encode(products['text_features'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3188ae30-f732-446d-9069-0de99d8c3900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-proj---PT\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db6d22-62de-4683-9689-756df33e1bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_texts = products['text_features'].tolist()\n",
    "resp = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=product_texts\n",
    ")\n",
    "product_embeddings = np.array([e.embedding for e in resp.data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128443b-882b-4af5-8e36-4817f80a3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_rag(user_id: int, top_k: int = 10):\n",
    "    if user_id not in users['user_id'].values:\n",
    "        return \"Usuario no encontrado\"\n",
    "\n",
    "    user = users[users['user_id'] == user_id].iloc[0]\n",
    "\n",
    "    # Embedding de intereses del usuario\n",
    "    user_text = \" \".join(user['intereses'])\n",
    "    user_emb = embed_model.encode(user_text, convert_to_tensor=True)\n",
    "\n",
    "    # Recuperación: top-k productos más similares\n",
    "    hits = util.semantic_search(user_emb, product_embeddings, top_k=top_k)[0]\n",
    "    top_products = products.iloc[[hit['corpus_id'] for hit in hits]]\n",
    "\n",
    "    # --------------------------\n",
    "    # 4️⃣ Generación con LLM\n",
    "    # --------------------------\n",
    "    client = OpenAI(api_key=\"TU_API_KEY_AQUI\")  # reemplaza con tu API key\n",
    "\n",
    "    # Formar prompt para el LLM\n",
    "    product_info = \"\\n\".join(\n",
    "        [f\"{row['name']} ({row['category']}): {row['text_features']}\" for _, row in top_products.iterrows()]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Eres un asistente que recomienda productos de bienestar.\n",
    "Usuario: edad {user['edad']}, género {user['genero']}, intereses: {', '.join(user['intereses'])}.\n",
    "Productos filtrados: {product_info}\n",
    "Sugiere 5 productos relevantes y explica brevemente por qué son útiles.\n",
    "Devuelve en JSON: [{\"product_id\": \"...\", \"name\": \"...\", \"category\": \"...\"}]\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a7d6b-f206-453b-aafd-e3e98dc93c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_rag(user_id=1, top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
